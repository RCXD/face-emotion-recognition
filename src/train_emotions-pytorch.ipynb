{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_DATA_DIR = '/home/HDD6TB/datasets/emotions/'\n",
    "INPUT_SIZE = (224, 224)\n",
    "#INPUT_SIZE = (299, 299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFFECT_DATA_DIR=ALL_DATA_DIR+'AffectNet/'\n",
    "AFFECT_TRAIN_DATA_DIR = AFFECT_DATA_DIR+'full_res/train'\n",
    "AFFECT_VAL_DATA_DIR = AFFECT_DATA_DIR+'full_res/val'\n",
    "AFFECT_SEVEN_TRAIN_DATA_DIR = AFFECT_DATA_DIR+'full_res/seven_emotions/train'\n",
    "AFFECT_SEVEN_VAL_DATA_DIR = AFFECT_DATA_DIR+'full_res/seven_emotions/val'\n",
    "\n",
    "AFFECT_IMG_TRAIN_DATA_DIR = AFFECT_DATA_DIR+str(INPUT_SIZE[0])+'/train'\n",
    "AFFECT_IMG_VAL_DATA_DIR = AFFECT_DATA_DIR+str(INPUT_SIZE[0])+'/val'\n",
    "AFFECT_IMG_SEVEN_TRAIN_DATA_DIR = AFFECT_DATA_DIR+str(INPUT_SIZE[0])+'/seven_emotions/train'\n",
    "AFFECT_IMG_SEVEN_VAL_DATA_DIR = AFFECT_DATA_DIR+str(INPUT_SIZE[0])+'/seven_emotions/val'\n",
    "AFFECT_TRAIN_ORIG_DATA_DIR = AFFECT_DATA_DIR+'orig/train'\n",
    "AFFECT_VAL_ORIG_DATA_DIR = AFFECT_DATA_DIR+'orig/val'\n",
    "\n",
    "IMG_AFFECT_DATA_DIR = AFFECT_DATA_DIR+'Manually_Annotated_Images/'\n",
    "AFFECT_TRAIN_FILE=AFFECT_DATA_DIR+'training.csv'\n",
    "AFFECT_TRAIN_FILTERED_FILE=AFFECT_DATA_DIR+'training_filtered.csv'\n",
    "AFFECT_VAL_FILE=AFFECT_DATA_DIR+'validation.csv'\n",
    "AFFECT_VAL_FILTERED_FILE=AFFECT_DATA_DIR+'validation_filtered.csv'\n",
    "\n",
    "AFFECT_TRAIN_ALIGNED_DATA_DIR = AFFECT_DATA_DIR+'full_res_aligned/train'# 8 emotions\n",
    "AFFECT_VAL_ALIGNED_DATA_DIR = AFFECT_DATA_DIR+'full_res_aligned/val'\n",
    "AFFECT_TRAIN_SEVEN_ALIGNED_DATA_DIR = AFFECT_DATA_DIR+'full_res_aligned/seven_emotions/train'# 7 emotions\n",
    "AFFECT_VAL_SEVEN_ALIGNED_DATA_DIR = AFFECT_DATA_DIR+'full_res_aligned/seven_emotions/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def save_csv(filename,outfile, dir_to_save):\n",
    "    affect_df = pd.read_csv(filename)\n",
    "    affect_vals=[d for i,d in affect_df.iterrows()]\n",
    "    with open(os.path.join(AFFECT_DATA_DIR,outfile), 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=['filepath','emotion','valence', 'arousal'])\n",
    "        writer.writeheader()\n",
    "        for d in affect_vals:\n",
    "            #print(d.subDirectory_filePath,d.face_x,d.face_y, d.face_width, d.face_height, d.expression)\n",
    "            if d.expression>=len(emotion_labels) or d.face_width<0:\n",
    "                continue\n",
    "            input_path=os.path.join(IMG_AFFECT_DATA_DIR,d.subDirectory_filePath)\n",
    "            dst_file_path=os.path.join(emotion_labels[d.expression],os.path.basename(d.subDirectory_filePath))\n",
    "            #print(input_path,dst_file_path)\n",
    "            if os.path.exists(os.path.join(dir_to_save,dst_file_path)):\n",
    "                #writer.writerow({'filepath':dst_file_path[len(AFFECT_DATA_DIR):],'emotion':emotion_labels[d.expression],'valence':d.valence, 'arousal':d.arousal})\n",
    "                writer.writerow({'filepath':dst_file_path,'emotion':emotion_labels[d.expression],'valence':d.valence, 'arousal':d.arousal})\n",
    "\n",
    "if False:\n",
    "    save_csv(AFFECT_VAL_FILE,AFFECT_VAL_FILTERED_FILE,AFFECT_IMG_VAL_DATA_DIR)\n",
    "    save_csv(AFFECT_TRAIN_FILE,AFFECT_TRAIN_FILTERED_FILE,AFFECT_IMG_TRAIN_DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.10.2+cu113\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "batch_size = 64 #48# 32# 32 #16 #8 #\n",
    "epochs = 40\n",
    "lr = 3e-5\n",
    "gamma = 0.7\n",
    "seed = 42\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/AffectNet/full_res/train /home/HDD6TB/datasets/emotions/AffectNet/full_res/val\n"
     ]
    }
   ],
   "source": [
    "#net_description='affectnet_'+net_description\n",
    "train_dir,test_dir=AFFECT_TRAIN_DATA_DIR,AFFECT_VAL_DATA_DIR\n",
    "#train_dir,test_dir=AFFECT_IMG_TRAIN_DATA_DIR,AFFECT_IMG_VAL_DATA_DIR\n",
    "#train_dir,test_dir=AFFECT_SEVEN_TRAIN_DATA_DIR,AFFECT_SEVEN_VAL_DATA_DIR\n",
    "#train_dir,test_dir=AFFECT_IMG_SEVEN_TRAIN_DATA_DIR,AFFECT_IMG_SEVEN_VAL_DATA_DIR\n",
    "#train_dir,test_dir=AFFECT_TRAIN_ORIG_DATA_DIR,AFFECT_VAL_ORIG_DATA_DIR\n",
    "\n",
    "#train_dir,test_dir=AFFECT_TRAIN_ALIGNED_DATA_DIR,AFFECT_VAL_ALIGNED_DATA_DIR\n",
    "#train_dir,test_dir=AFFECT_TRAIN_SEVEN_ALIGNED_DATA_DIR,AFFECT_VAL_SEVEN_ALIGNED_DATA_DIR\n",
    "\n",
    "print(train_dir,test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ENET2=True #False #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(260, 260), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE=260 if USE_ENET2 else 224 # 300 # 80 #\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "print(test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
    "def set_parameter_requires_grad(model, requires_grad):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FER only model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/home/HDD6TB/datasets/emotions/AffectNet/full_res/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17080/2231824986.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'num_workers'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pin_memory'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_transforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mis_valid_file\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     ):\n\u001b[1;32m--> 310\u001b[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001b[0m\u001b[0;32m    311\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    143\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[0;32m    144\u001b[0m                                             target_transform=target_transform)\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torchvision\\datasets\\folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \"\"\"\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/home/HDD6TB/datasets/emotions/AffectNet/full_res/train'"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transforms)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(train_dataset.targets, return_counts=True)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "num_classes=len(train_dataset.classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# loss function\n",
    "weights = torch.FloatTensor(list(class_weights.values())).cuda()\n",
    "if False:\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    def label_smooth(target, n_classes: int, label_smoothing=0.1):\n",
    "        # convert to one-hot\n",
    "        batch_size = target.size(0)\n",
    "        target = torch.unsqueeze(target, 1)\n",
    "        soft_target = torch.zeros((batch_size, n_classes), device=target.device)\n",
    "        soft_target.scatter_(1, target, 1)\n",
    "        # label smoothing\n",
    "        soft_target = soft_target * (1 - label_smoothing) + label_smoothing / n_classes\n",
    "        return soft_target\n",
    "\n",
    "    def cross_entropy_loss_with_soft_target(pred, soft_target):\n",
    "        #logsoftmax = nn.LogSoftmax(dim=-1)\n",
    "        return torch.mean(torch.sum(- weights*soft_target * torch.nn.functional.log_softmax(pred, -1), 1))\n",
    "\n",
    "    def cross_entropy_with_label_smoothing(pred, target):\n",
    "        soft_target = label_smooth(target, pred.size(1)) #num_classes) #\n",
    "        return cross_entropy_loss_with_soft_target(pred, soft_target)\n",
    "\n",
    "    criterion=cross_entropy_with_label_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from robust_optimization import RobustOptimizer\n",
    "import copy\n",
    "def train(model,n_epochs=epochs, learningrate=lr, robust=False):\n",
    "    # optimizer\n",
    "    if robust:\n",
    "        optimizer = RobustOptimizer(filter(lambda p: p.requires_grad, model.parameters()), optim.Adam, lr=learningrate)\n",
    "        #print(optimizer)\n",
    "    else:\n",
    "        optimizer=optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learningrate)\n",
    "    # scheduler\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    best_acc=0\n",
    "    best_model=None\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        model.train()\n",
    "        for data, label in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            if robust:\n",
    "                #optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "  \n",
    "                # second forward-backward pass\n",
    "                output = model(data)\n",
    "                loss = criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == label).float().sum()\n",
    "            epoch_accuracy += acc\n",
    "            epoch_loss += loss\n",
    "        epoch_accuracy /= len(train_dataset)\n",
    "        epoch_loss /= len(train_dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            for data, label in test_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().sum()\n",
    "                epoch_val_accuracy += acc\n",
    "                epoch_val_loss += val_loss\n",
    "        epoch_val_accuracy /= len(test_dataset)\n",
    "        epoch_val_loss /= len(test_dataset)\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "        if best_acc<epoch_val_accuracy:\n",
    "            best_acc=epoch_val_accuracy\n",
    "            best_model=copy.deepcopy(model.state_dict())\n",
    "        #scheduler.step()\n",
    "    \n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best acc:{best_acc}\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            for data, label in test_loader:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                val_output = model(data)\n",
    "                val_loss = criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output.argmax(dim=1) == label).float().sum()\n",
    "                epoch_val_accuracy += acc\n",
    "                epoch_val_loss += val_loss\n",
    "        epoch_val_accuracy /= len(test_dataset)\n",
    "        epoch_val_loss /= len(test_dataset)\n",
    "        print(\n",
    "            f\"val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f}\\n\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"No best model Best acc:{best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet101,mobilenet_v2\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "model=timm.create_model('tf_efficientnet_b0_ns', pretrained=False)\n",
    "model.classifier=torch.nn.Identity()\n",
    "model.load_state_dict(torch.load('../models/pretrained_faces/state_vggface2_enet0_new.pt')) #_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "model.classifier=nn.Sequential(nn.Linear(in_features=1280, out_features=num_classes)) #1792 #1280 #1536\n",
    "#model.head.fc=nn.Linear(in_features=3072, out_features=num_classes)\n",
    "#model.head=nn.Sequential(nn.Linear(in_features=768, out_features=num_classes))\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=False)\n",
    "set_parameter_requires_grad(model.classifier, requires_grad=True)\n",
    "train(model,3,0.001,robust=True)\n",
    "#Best acc:0.48875007033348083\n",
    "#7: Best acc:0.558712363243103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=True)\n",
    "train(model,6,1e-4,robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "if USE_ENET2:\n",
    "    if False: # 7 emotions\n",
    "        PATH='../models/affectnet_emotions/enet_b2_7.pt'\n",
    "        model_name='enet2_7_pt'\n",
    "    else:\n",
    "        #PATH='../models/affectnet_emotions/enet_b2_8.pt'\n",
    "        PATH='../models/affectnet_emotions/enet_b2_8_best.pt'\n",
    "        model_name='enet2_8_pt'\n",
    "else:\n",
    "    if False: # 7 emotions from AFFECT_IMG_SEVEN_TRAIN_DATA_DIR and AFFECT_IMG_SEVEN_VAL_DATA_DIR\n",
    "        PATH='../models/affectnet_emotions/enet_b0_7.pt'\n",
    "        model_name='enet0_7_pt'\n",
    "    else:\n",
    "        PATH='../models/affectnet_emotions/enet_b0_8_best_vgaf.pt'\n",
    "        #PATH='../models/affectnet_emotions/enet_b0_8_best_afew.pt'\n",
    "        model_name='enet0_8_pt'\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Save\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# Load\n",
    "print(PATH)\n",
    "model = torch.load(PATH)\n",
    "model=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "class_to_idx=train_dataset.class_to_idx\n",
    "print(class_to_idx)\n",
    "idx_to_class={idx:cls for cls,idx in class_to_idx.items()}\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "print(test_dir)\n",
    "y_val,y_scores_val=[],[]\n",
    "model.eval()\n",
    "for class_name in tqdm(os.listdir(test_dir)):\n",
    "    if class_name in class_to_idx:\n",
    "        class_dir=os.path.join(test_dir,class_name)\n",
    "        y=class_to_idx[class_name]\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            filepath=os.path.join(class_dir,img_name)\n",
    "            img = Image.open(filepath)\n",
    "            img_tensor = test_transforms(img)\n",
    "            img_tensor.unsqueeze_(0)\n",
    "            scores = model(img_tensor.to(device))\n",
    "            scores=scores[0].data.cpu().numpy()\n",
    "            #print(scores.shape)\n",
    "            y_scores_val.append(scores)\n",
    "            y_val.append(y)\n",
    "\n",
    "y_scores_val=np.array(y_scores_val)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "y_pred=np.argmax(y_scores_val,axis=1)\n",
    "acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "print(acc)\n",
    "\n",
    "y_train=np.array(train_dataset.targets)\n",
    "\n",
    "for i in range(y_scores_val.shape[1]):\n",
    "    _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n",
    "    print('%s %d/%d acc: %f' %(idx_to_class[i],(y_train==i).sum(),(y_val==i).sum(),100*_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#-Contempt\n",
    "сontempt_idx=class_to_idx['Contempt']\n",
    "y_scores_val_filtered=y_scores_val[:, [i!=сontempt_idx for i in idx_to_class]]\n",
    "print(y_scores_val_filtered.shape)\n",
    "y_pred_filtered=np.argmax(y_scores_val_filtered,axis=1)\n",
    "other_indices=y_val!=сontempt_idx\n",
    "y_val_new=np.array([y if y<сontempt_idx else y-1 for y in y_val if y!=сontempt_idx])\n",
    "acc=100.0*np.mean(y_val_new==y_pred_filtered[other_indices])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "labels=list(class_to_idx.keys())\n",
    "print(labels)\n",
    "IC = type('IdentityClassifier', (), {\"predict\": lambda i : i, \"_estimator_type\": \"classifier\"})\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "def plt_conf_matrix(y_true,y_pred,labels):\n",
    "    print(y_pred.shape,y_true.shape, (y_pred==y_true).mean())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    plot_confusion_matrix(IC, y_pred,y_true,display_labels=labels,cmap=plt.cm.Blues,ax=ax,colorbar=False) #,normalize='true'\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plt_conf_matrix(y_val,y_pred,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "labels_7=[idx_to_class[i] for i in idx_to_class if i!=сontempt_idx]#list(class_to_idx.keys())\n",
    "print(labels_7)\n",
    "plt_conf_matrix(y_val_new, y_pred_filtered[other_indices],labels_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task: FER+Valence-Arousal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "affectnet_expr2emotion={0:'Neutral',1:'Happiness', 2:'Sadness', 3:'Surprise', 4:'Fear', 5:'Disgust', 6:'Anger', 7:'Contempt'}\n",
    "idx_to_class={0: 'Anger', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happiness', 5: 'Neutral', 6: 'Sadness', 7: 'Surprise'}\n",
    "#idx_to_class={0: 'Anger', 1: 'Disgust', 2: 'Fear', 3: 'Happiness', 4: 'Neutral', 5: 'Sadness', 6: 'Surprise'}\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "class MultiTaskDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,csv_file, root, transform):\n",
    "        df=pd.read_csv(csv_file)\n",
    "        df=df[df['emotion'].isin(class_to_idx.keys())]\n",
    "        self.paths = list(df.filepath)#[:4000]\n",
    "        self.targets = np.array([class_to_idx[cls] for cls in df.emotion])#[:4000]\n",
    "        self.valence_arousal = df[['valence','arousal']].to_numpy()#[:4000]\n",
    "        self.transform = transform\n",
    "        self.root=root\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #dealing with the image\n",
    "        img = Image.open(os.path.join(self.root,self.paths[idx])).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        #dealing with the labels\n",
    "        emotion_label = self.targets[idx]\n",
    "        valence=torch.tensor(float(self.valence_arousal[idx,0]), dtype=torch.float32)\n",
    "        arousal=torch.tensor(float(self.valence_arousal[idx,1]), dtype=torch.float32)\n",
    "        \n",
    "        return img.data, (emotion_label, valence, arousal)\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "batch_size=48\n",
    "train_dataset = MultiTaskDataset(csv_file=AFFECT_TRAIN_FILTERED_FILE, root=train_dir, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_dataset = MultiTaskDataset(csv_file=AFFECT_VAL_FILTERED_FILE,root=test_dir, transform=test_transforms)\n",
    "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs) \n",
    "\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(train_dataset.targets, return_counts=True)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights.values())\n",
    "\n",
    "num_classes=len(class_to_idx)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import timm\n",
    "model=timm.create_model('tf_efficientnet_b0_ns', pretrained=False)\n",
    "model.classifier=torch.nn.Identity()\n",
    "model.load_state_dict(torch.load('../models/pretrained_faces/state_vggface2_enet0_new.pt')) #_new\n",
    "model.classifier=nn.Linear(in_features=1280, out_features=num_classes+2) #1792 #1280 #1536 #1408\n",
    "model=model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def ConcordanceCorCoeff(prediction, ground_truth):\n",
    "    mean_gt = torch.mean (ground_truth, 0)\n",
    "    mean_pred = torch.mean (prediction, 0)\n",
    "    var_gt = torch.var (ground_truth, 0)\n",
    "    var_pred = torch.var (prediction, 0)\n",
    "    v_pred = prediction - mean_pred\n",
    "    v_gt = ground_truth - mean_gt\n",
    "    cor = torch.sum (v_pred * v_gt) / (torch.sqrt(torch.sum(v_pred ** 2)) * torch.sqrt(torch.sum(v_gt ** 2)))\n",
    "    sd_gt = torch.std(ground_truth)\n",
    "    sd_pred = torch.std(prediction)\n",
    "    numerator=2*cor*sd_gt*sd_pred\n",
    "    denominator=var_gt+var_pred+(mean_gt-mean_pred)**2\n",
    "    ccc = numerator/denominator\n",
    "    return ccc\n",
    "\n",
    "def ConcordanceCorCoeffLoss(prediction, ground_truth):\n",
    "    return (1-ConcordanceCorCoeff(prediction, ground_truth))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "class MultiTaskLossWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskLossWrapper, self).__init__()\n",
    "        #self.task_num = 3\n",
    "        #self.log_vars = nn.Parameter(torch.zeros((self.task_num)))\n",
    "        weights = torch.FloatTensor(list(class_weights.values())).to(device)\n",
    "        self.loss_emotions = nn.CrossEntropyLoss(weight=weights)\n",
    "        self.loss_valence=ConcordanceCorCoeffLoss #nn.MSELoss()\n",
    "        self.loss_arousal=ConcordanceCorCoeffLoss #nn.MSELoss()\n",
    "\n",
    "    def forward(self, preds, target):\n",
    "        loss_emotions=self.loss_emotions(preds[:,:num_classes],target[0])\n",
    "        loss_valence=self.loss_valence(preds[:,num_classes],target[1])\n",
    "        loss_arousal=self.loss_arousal(preds[:,num_classes+1],target[2])\n",
    "        return loss_emotions+(loss_valence+loss_arousal)*1\n",
    "my_criterion=MultiTaskLossWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from robust_optimization import RobustOptimizer\n",
    "import copy\n",
    "def train(model,n_epochs=epochs, learningrate=lr, robust=False):\n",
    "    # optimizer\n",
    "    if robust:\n",
    "        optimizer = RobustOptimizer(filter(lambda p: p.requires_grad, model.parameters()), optim.Adam, lr=learningrate)\n",
    "        #print(optimizer)\n",
    "    else:\n",
    "        optimizer=optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learningrate)\n",
    "    # scheduler\n",
    "    #scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    best_acc=0\n",
    "    best_model=None\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        epoch_mse_valence=epoch_mse_arousal=0\n",
    "        model.train()\n",
    "        for data, label in tqdm(train_loader):\n",
    "            data = data.to(device)\n",
    "            label = [l.to(device) for l in label]\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = my_criterion(output, label)\n",
    "\n",
    "            if robust:\n",
    "                #optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.first_step(zero_grad=True)\n",
    "  \n",
    "                # second forward-backward pass\n",
    "                output = model(data)\n",
    "                loss = my_criterion(output, label)\n",
    "                loss.backward()\n",
    "                optimizer.second_step(zero_grad=True)\n",
    "            else:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            acc = (output[:,:num_classes].argmax(dim=1) == label[0]).float().sum()\n",
    "            epoch_accuracy += acc\n",
    "            \n",
    "            mse_valense = ((output[:,num_classes] - label[1])**2).float().sum()\n",
    "            epoch_mse_valence += mse_valense\n",
    "            mse_arousal = ((output[:,num_classes+1] - label[2])**2).float().sum()\n",
    "            epoch_mse_arousal += mse_arousal\n",
    "            \n",
    "            epoch_loss += loss\n",
    "\n",
    "        epoch_accuracy /= len(train_dataset)\n",
    "        mse_valense /= len(train_dataset)\n",
    "        mse_arousal /= len(train_dataset)\n",
    "        epoch_loss /= len(train_dataset)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_val_accuracy = 0\n",
    "            epoch_val_loss = 0\n",
    "            epoch_val_mse_valence=epoch_val_mse_arousal=0\n",
    "            for data, label in test_loader:\n",
    "                data = data.to(device)\n",
    "                label = [l.to(device) for l in label]\n",
    "                \n",
    "                val_output = model(data)\n",
    "                val_loss = my_criterion(val_output, label)\n",
    "\n",
    "                acc = (val_output[:,:num_classes].argmax(dim=1) == label[0]).float().sum()\n",
    "                epoch_val_accuracy += acc\n",
    "\n",
    "                mse_valense = ((val_output[:,num_classes] - label[1])**2).float().sum()\n",
    "                epoch_val_mse_valence += mse_valense\n",
    "                mse_arousal = ((val_output[:,num_classes+1] - label[2])**2).float().sum()\n",
    "                epoch_val_mse_arousal += mse_arousal\n",
    "                epoch_val_loss += val_loss\n",
    "        \n",
    "        epoch_val_accuracy /= len(test_dataset)\n",
    "        epoch_val_mse_valence /= len(test_dataset)\n",
    "        epoch_val_mse_arousal /= len(test_dataset)\n",
    "        epoch_val_loss /= len(test_dataset)\n",
    "        print(\n",
    "            f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - mse (valence): {epoch_mse_valence:.4f} - mse (arousal): {epoch_mse_arousal:.4f} - val_loss : {epoch_val_loss:.4f} - val_acc: {epoch_val_accuracy:.4f} - val_mse (valence): {epoch_val_mse_valence:.4f} - val_mse (arousal): {epoch_val_mse_arousal:.4f}\\n\"\n",
    "        )\n",
    "        if best_acc<epoch_val_accuracy:\n",
    "            best_acc=epoch_val_accuracy\n",
    "            best_model=copy.deepcopy(model.state_dict())\n",
    "        #scheduler.step()\n",
    "    \n",
    "    if best_model is not None:\n",
    "        model.load_state_dict(best_model)\n",
    "        print(f\"Best acc:{best_acc}\")\n",
    "    else:\n",
    "        print(f\"No best model Best acc:{best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=False)\n",
    "set_parameter_requires_grad(model.classifier, requires_grad=True)\n",
    "train(model,3,0.001,robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "set_parameter_requires_grad(model, requires_grad=True)\n",
    "train(model,6,1e-4,robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "PATH='../models/affectnet_emotions/enet_b0_8_va_mtl.pt'\n",
    "model_name='enet0_8_mtl_pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "print(PATH)\n",
    "if False:\n",
    "    torch.save(model, PATH)\n",
    "else:\n",
    "    model = torch.load(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "model=model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    epoch_val_accuracy = 0\n",
    "    epoch_val_mse_valence=epoch_val_mse_arousal=0\n",
    "    for data, label in test_loader:\n",
    "        data = data.to(device)\n",
    "        label = [l.to(device) for l in label]\n",
    "\n",
    "        val_output = model(data)\n",
    "\n",
    "        acc = (val_output[:,:num_classes].argmax(dim=1) == label[0]).float().sum()\n",
    "        epoch_val_accuracy += acc\n",
    "\n",
    "        mse_valense = ((val_output[:,num_classes] - label[1])**2).float().sum()\n",
    "        epoch_val_mse_valence += mse_valense\n",
    "        mse_arousal = ((val_output[:,num_classes+1] - label[2])**2).float().sum()\n",
    "        epoch_val_mse_arousal += mse_arousal\n",
    "epoch_val_accuracy /= len(test_dataset)\n",
    "epoch_val_mse_valence /= len(test_dataset)\n",
    "epoch_val_mse_arousal /= len(test_dataset)\n",
    "print(\n",
    "    f\"val_acc: {epoch_val_accuracy:.4f} - val_mse (valence): {epoch_val_mse_valence:.4f} - val_mse (arousal): {epoch_val_mse_arousal:.4f}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "y_val,y_scores_val=[],[]\n",
    "model.eval()\n",
    "for class_name in tqdm(os.listdir(test_dir)):\n",
    "    if class_name in class_to_idx:\n",
    "        class_dir=os.path.join(test_dir,class_name)\n",
    "        y=class_to_idx[class_name]\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            filepath=os.path.join(class_dir,img_name)\n",
    "            img = Image.open(filepath)\n",
    "            img_tensor = test_transforms(img)\n",
    "            img_tensor.unsqueeze_(0)\n",
    "            scores = model(img_tensor.to(device))\n",
    "            scores=scores[0].data.cpu().numpy()\n",
    "            #print(scores.shape)\n",
    "            y_scores_val.append(scores[:-2])\n",
    "            y_val.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "y_scores_val=np.array(y_scores_val)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_val.shape,y_val.shape)\n",
    "\n",
    "y_pred=np.argmax(y_scores_val,axis=1)\n",
    "acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "print(acc)\n",
    "\n",
    "y_train=np.array(train_dataset.targets)\n",
    "for i in range(y_scores_val.shape[1]):\n",
    "    _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n",
    "    print('%s %d/%d acc: %f' %(idx_to_class[i],(y_train==i).sum(),(y_val==i).sum(),100*_val_acc))\n",
    "\n",
    "#-Contempt\n",
    "сontempt_idx=class_to_idx['Contempt']\n",
    "y_scores_val_filtered=y_scores_val[:, [i!=сontempt_idx for i in idx_to_class]]\n",
    "print(y_scores_val_filtered.shape)\n",
    "y_pred=np.argmax(y_scores_val_filtered,axis=1)\n",
    "other_indices=y_val!=сontempt_idx\n",
    "y_val_new=np.array([y if y<сontempt_idx else y-1 for y in y_val if y!=сontempt_idx])\n",
    "acc=100.0*np.mean(y_val_new==y_pred[other_indices])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "affect_df = pd.read_csv(AFFECT_VAL_FILE)\n",
    "X_VA_val=[]\n",
    "VA_preds=[]\n",
    "for i,d in tqdm(affect_df.iterrows()):\n",
    "    if d.expression not in affectnet_expr2emotion:\n",
    "        continue\n",
    "    X_VA_val.append([d.valence, d.arousal])\n",
    "    img = Image.open(os.path.join(test_dir,affectnet_expr2emotion[d.expression],os.path.basename(d.subDirectory_filePath))).convert('RGB')\n",
    "    img_tensor = test_transforms(img)\n",
    "    img_tensor.unsqueeze_(0)\n",
    "    scores = model(img_tensor.to(device))\n",
    "    scores=scores[0].data.cpu().numpy()\n",
    "    VA_preds.append([scores[-2],scores[-1]])\n",
    "X_VA_val=np.array(X_VA_val)\n",
    "VA_preds=np.array(VA_preds)\n",
    "print(X_VA_val.shape,VA_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "print('Valence,Arousal')\n",
    "mse=((X_VA_val-VA_preds)**2).mean(axis=0)\n",
    "print('MSE',mse)\n",
    "print('RMSE',np.sqrt(mse))\n",
    "print('MAE',abs((X_VA_val-VA_preds)).mean(axis=0))\n",
    "print('CCC',ConcordanceCorCoeff(torch.from_numpy(X_VA_val[:,0]),torch.from_numpy(VA_preds[:,0])).numpy(),\n",
    "      ConcordanceCorCoeff(torch.from_numpy(X_VA_val[:,1]),torch.from_numpy(VA_preds[:,1])).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "from facial_analysis import FacialImageProcessing\n",
    "imgProcessing=FacialImageProcessing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fpath='../test_images/20180720_174416.jpg'\n",
    "frame_bgr=cv2.imread(fpath)\n",
    "plt.figure(figsize=(5, 5))\n",
    "frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(frame)\n",
    "bounding_boxes, points = imgProcessing.detect_faces(frame)\n",
    "points = points.T\n",
    "for bbox,p in zip(bounding_boxes, points):\n",
    "    box = bbox.astype(np.int)\n",
    "    x1,y1,x2,y2=box[0:4]    \n",
    "    face_img=frame[y1:y2,x1:x2,:]\n",
    "    \n",
    "    img_tensor = test_transforms(Image.fromarray(face_img))\n",
    "    img_tensor.unsqueeze_(0)\n",
    "    scores = model(img_tensor.to(device))\n",
    "    scores=scores[0].data.cpu().numpy()\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(face_img)\n",
    "    if False:\n",
    "        plt.title(idx_to_class[np.argmax(scores)])\n",
    "    else:\n",
    "        plt.title(f\"{idx_to_class[np.argmax(scores[:8])]} V:{scores[8]:.2f} A:{scores[9]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "imgProcessing.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "feature_extractor_model = torch.load(PATH)\n",
    "feature_extractor_model.classifier=torch.nn.Identity()\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "DATA_DIR=os.path.join(ALL_DATA_DIR,'EmotiW/AFEW/')\n",
    "print(DATA_DIR)\n",
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def get_features(data_dir):\n",
    "    filename2features={}\n",
    "    for filename in tqdm(os.listdir(data_dir)):\n",
    "        frames_dir=os.path.join(data_dir,filename)\n",
    "        X_global_features,X_isface=[],[]\n",
    "        imgs=[]\n",
    "        for img_name in os.listdir(frames_dir):\n",
    "            img = Image.open(os.path.join(frames_dir,img_name))\n",
    "            img_tensor = test_transforms(img)\n",
    "            X_isface.append('noface' not in img_name)\n",
    "                \n",
    "            if img.size:\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=16:        \n",
    "                    #global_features,feats,scores=feature_extractor_model.predict(inp)\n",
    "                    scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    scores=scores.data.cpu().numpy()\n",
    "                    #print(scores.shape)\n",
    "            \n",
    "                    #print(global_features.shape,feats.shape,scores.shape)\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=scores\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,scores),axis=0)\n",
    "                    \n",
    "                    imgs=[]\n",
    "\n",
    "        if len(imgs)>0:        \n",
    "            scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "            scores=scores.data.cpu().numpy()\n",
    "            #print(scores.shape)\n",
    "\n",
    "            #print(global_features.shape,feats.shape,scores.shape)\n",
    "            if len(X_global_features)==0:\n",
    "                X_global_features=scores\n",
    "            else:\n",
    "                X_global_features=np.concatenate((X_global_features,scores),axis=0)\n",
    "\n",
    "        X_isface=np.array(X_isface)\n",
    "        #print(X_global_features.shape,X_feats.shape,X_scores.shape)\n",
    "        filename2features[filename]=(X_global_features,X_isface)\n",
    "    return filename2features\n",
    "\n",
    "filename2features_val=get_features(os.path.join(DATA_DIR,'val/AlignedFaces_LBPTOP_Points_Val/frames_mtcnn_cropped/'))\n",
    "filename2features_train=get_features(os.path.join(DATA_DIR,'train/AlignedFaces_LBPTOP_Points/frames_mtcnn_cropped/')) #_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_feat_emotiw.pickle' #'_feat_bgr_emotiw.pickle'\n",
    "\n",
    "#MODEL2EMOTIW_FEATURES='enet0_vggface2_new1_pt_feat_emotiw.pickle'\n",
    "#MODEL2EMOTIW_FEATURES='enet0_vggface2_pt_feat_emotiw.pickle'\n",
    "print(MODEL2EMOTIW_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'wb') as handle:\n",
    "    pickle.dump([filename2features_train,filename2features_val], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    filename2features_train,filename2features_val=pickle.load(handle)\n",
    "print(len(filename2features_train),len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def create_dataset(filename2features,data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    for category in emotion_to_index:\n",
    "        for filename in os.listdir(os.path.join(data_dir,category)):\n",
    "            fn=os.path.splitext(filename)[0]\n",
    "            if not fn in filename2features:\n",
    "                continue\n",
    "            features=filename2features[fn]\n",
    "            total_features=None\n",
    "            if True:\n",
    "                #prev=features[0].shape\n",
    "                cur_features=features[0][features[-1]==1]\n",
    "                #print(prev,features.shape)\n",
    "            else:\n",
    "                cur_features=features[0]\n",
    "            if len(cur_features)==0:\n",
    "                has_faces.append(0)\n",
    "                total_features=np.zeros_like(feature)\n",
    "            else:\n",
    "                has_faces.append(1)\n",
    "                #mean_features=features.mean(axis=0)\n",
    "                mean_features = (np.mean(cur_features, axis=0))\n",
    "                std_features = (np.std(cur_features, axis=0))\n",
    "                max_features = (np.max(cur_features, axis=0))\n",
    "                min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "            \n",
    "            if total_features is not None:\n",
    "                x.append(total_features)\n",
    "                y.append(emotion_to_index[category])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,has_faces\n",
    "\n",
    "x_train, y_train, has_faces_train = create_dataset(filename2features_train,os.path.join(DATA_DIR,'train'))\n",
    "x_test, y_test, has_faces_test = create_dataset(filename2features_val,os.path.join(DATA_DIR,'val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "x_train_norm=preprocessing.normalize(x_train,norm='l2')\n",
    "x_test_norm=preprocessing.normalize(x_test,norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#clf = svm.LinearSVC(C=3.5) #0.5 1.1\n",
    "clf = svm.LinearSVC(C=1.1) \n",
    "#clf = svm.SVC(kernel='rbf')\n",
    "#np.random.seed(1)\n",
    "#clf=RandomForestClassifier(n_estimators=1000,max_depth=7, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    clf.fit(x_train_norm[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test_norm)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[has_faces_test==1], y_pred[has_faces_test==1]))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "DATA_DIR='/home/HDD6TB/datasets/emotions/EmotiW/VGAF/'\n",
    "print(DATA_DIR)\n",
    "emotion_to_index = {'Positive':1, 'Neutral':2, 'Negative':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "def get_features_scores(data_dir):\n",
    "    videoname2features={}\n",
    "    for videoname in tqdm(os.listdir(data_dir)):\n",
    "        frames_dir=os.path.join(data_dir,videoname)\n",
    "        X_global_features=[]\n",
    "        for filename in sorted(os.listdir(frames_dir)):\n",
    "            faces_dir=os.path.join(frames_dir,filename)\n",
    "            imgs=[]\n",
    "            global_features=[]\n",
    "            for img_name in sorted(os.listdir(faces_dir)):\n",
    "                img = Image.open(os.path.join(faces_dir,img_name))\n",
    "                img_tensor = test_transforms(img)\n",
    "                \n",
    "                if img.size:\n",
    "                    imgs.append(img_tensor)\n",
    "                    if len(imgs)>=32:        \n",
    "                        #global_features,feats,scores=feature_extractor_model.predict(inp)\n",
    "                        scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                        scores=scores.data.cpu().numpy()\n",
    "                        #print(scores.shape)\n",
    "\n",
    "                        if len(global_features)==0:\n",
    "                            global_features=scores\n",
    "                        else:\n",
    "                            global_features=np.concatenate((global_features,scores),axis=0)\n",
    "\n",
    "                        imgs=[]\n",
    "\n",
    "\n",
    "            if len(imgs)>0:        \n",
    "                scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                scores=scores.data.cpu().numpy()\n",
    "                #print(scores.shape)\n",
    "\n",
    "                if len(global_features)==0:\n",
    "                    global_features=scores\n",
    "                else:\n",
    "                    global_features=np.concatenate((global_features,scores),axis=0)\n",
    "                #print(videoname,filename,global_features.shape)\n",
    "                X_global_features.append(global_features)\n",
    "        \n",
    "        #print(videoname,len(X_global_features))\n",
    "        videoname2features[videoname]=X_global_features\n",
    "    return videoname2features\n",
    "\n",
    "video2Allfeatures_val=get_features_scores(os.path.join(DATA_DIR,'preprocessed/Val/mtcnn_aligned'))\n",
    "video2Allfeatures_train=get_features_scores(os.path.join(DATA_DIR,'preprocessed/Train/mtcnn_aligned'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#model_name='mobilenet_v1_ft'\n",
    "#MODEL2EMOTIW_FEATURES=model_name+'_feat_vgaf.pickle' #'_feat_bgr_emotiw.pickle'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_feat_vgaf_aligned.pickle'\n",
    "#MODEL2EMOTIW_FEATURES=model_name+'_feat_emotiw_cropped.pickle'\n",
    "\n",
    "#MODEL2EMOTIW_FEATURES='enet0_vggface2_new1_pt_feat_vgaf_aligned.pickle'\n",
    "#MODEL2EMOTIW_FEATURES='enet0_vggface2_pt_feat_vgaf_aligned.pickle'\n",
    "print(MODEL2EMOTIW_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'wb') as handle:\n",
    "    pickle.dump([video2Allfeatures_train,video2Allfeatures_val], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    video2Allfeatures_train,video2Allfeatures_val=pickle.load(handle)\n",
    "print(len(video2Allfeatures_train),len(video2Allfeatures_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def create_dataset(videoname2features,labelsfile):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    with open(labelsfile, mode='r') as csvfile:\n",
    "        labels_reader = csv.reader(csvfile, delimiter=' ')\n",
    "        for i,row in enumerate(labels_reader):\n",
    "            if i==0:\n",
    "                #print('first:',row)\n",
    "                continue\n",
    "            videoname,label=row[0],int(row[1])\n",
    "            X_global_features=videoname2features[videoname]\n",
    "            #print(videoname,label,len(X_global_features))\n",
    "            \n",
    "            total_features=[]\n",
    "            for cur_features in X_global_features:\n",
    "                #print(cur_features.shape)\n",
    "                mean_features = (np.mean(cur_features, axis=0))\n",
    "                std_features = (np.std(cur_features, axis=0))\n",
    "                max_features = (np.max(cur_features, axis=0))\n",
    "                min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                feature = np.concatenate((mean_features,std_features), axis=None)\n",
    "                #feature=max_features\n",
    "                \n",
    "                total_features.append(feature)\n",
    "            \n",
    "            if len(total_features)>0:\n",
    "                total_features=np.array(total_features)\n",
    "                mean_features = (np.mean(total_features, axis=0))\n",
    "                std_features = (np.std(total_features, axis=0))\n",
    "                max_features = (np.max(total_features, axis=0))\n",
    "                min_features = (np.min(total_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                feature = np.concatenate((mean_features,std_features), axis=None)\n",
    "                #feature=max_features\n",
    "                x.append(feature)\n",
    "                has_faces.append(1)\n",
    "            else:\n",
    "                x.append(np.zeros_like(feature))\n",
    "                has_faces.append(0)\n",
    "            y.append(label-1)\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,has_faces\n",
    "\n",
    "x_train, y_train, has_faces_train = create_dataset(video2Allfeatures_train,os.path.join(DATA_DIR,'Train_labels.txt'))\n",
    "x_test, y_test, has_faces_test = create_dataset(video2Allfeatures_val,os.path.join(DATA_DIR,'Val_labels.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "x_train_norm=preprocessing.normalize(x_train,norm='l2')\n",
    "x_test_norm=preprocessing.normalize(x_test,norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'win32api'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "#clf = svm.LinearSVC(C=0.01) #0.25 0.5\n",
    "clf = svm.SVC(kernel='rbf',C=1.9)\n",
    "#np.random.seed(1)\n",
    "#clf=RandomForestClassifier(n_estimators=1000,max_depth=7, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    clf.fit(x_train_norm[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test_norm)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[has_faces_test==1], y_pred[has_faces_test==1]))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c40fc240bea52273cd1a1858a71b7744abb2d3b41121723fab477901189220d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
